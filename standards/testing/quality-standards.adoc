= Quality Standards and Testing Framework
:toc: left
:toclevels: 3
:toc-title: Table of Contents
:sectnums:
:source-highlighter: highlight.js

== Purpose

This document defines comprehensive quality standards, testing framework guidelines, and quality verification processes for CUI OSS projects.

== Related Documentation

* xref:core-standards.adoc[Testing Standards Overview]
* xref:core-standards.adoc[Core Testing Standards]
* xref:cui-test-generator-guide.adoc[CUI Test Generator Usage Guide]
* xref:../logging/testing-guide.adoc[Logging Testing Guide]
* xref:../documentation/javadoc-standards.adoc[Javadoc Standards]
* xref:../java/java-code-standards.adoc[Java Standards]

== Core Testing Standards

=== Test Structure and Organization

* Follow AAA pattern (Arrange-Act-Assert)
* One logical assertion per test
* Clear test naming convention
* Descriptive test documentation
* Independent test execution
* Clean test environment
* Predictable test data

[[coverage-requirements]]
=== Coverage Requirements

* Minimum 80% line coverage
* Minimum 80% branch coverage
* Critical paths must have 100% coverage
* All public APIs must be tested
* Edge cases must be covered
* No coverage regressions allowed
* Regular coverage review
* Use Maven profile `-Pcoverage` for verifying coverage metrics

=== Testing Tools and Frameworks

[[testing-library-restrictions]]
==== Testing Library Requirements

Strict compliance with approved testing libraries to ensure consistency and compatibility:

**ALLOWED LIBRARIES:**

* **cui-test-libs**: All CUI testing utilities and frameworks (required for CUI projects)
* **junit-jupiter**: JUnit 5 for all test execution and assertions
* **awaitility**: For asynchronous testing, waiting conditions, and polling
* **rest-assured**: For REST API testing, HTTP request/response validation

**FORBIDDEN LIBRARIES:**

* **Mockito**: Do NOT use for mocking - use CUI framework alternatives instead
* **PowerMock**: Do NOT use for advanced mocking scenarios - refactor to use dependency injection
* **Hamcrest**: Do NOT use for assertions - use JUnit 5 assertions exclusively

**Migration Guidelines:**

* Replace Mockito with CUI framework dependency injection patterns
* Convert Hamcrest matchers to JUnit 5 assertion methods
* Use cui-test-mockwebserver-junit5 for HTTP mocking instead of Mockito
* Leverage cui-test-generator for test data creation instead of manual or random approaches

==== Required Frameworks

1. JUnit 5
   * Use `@DisplayName` for readable test names
   * Leverage parameterized tests (see <<parameterized-tests-best-practices,Parameterized Tests Best Practices>>)
   * Apply proper test lifecycle annotations

==== CUI Testing Utilities

1. **CUI Framework Compliance**: All testing must follow xref:core-standards.adoc#cui-framework-requirements[CUI Framework Requirements]
   * See xref:cui-test-generator-guide.adoc[CUI Test Generator Usage Guide] for implementation examples
   * See xref:core-standards.adoc[Core Standards] for mandatory framework requirements

2. https://github.com/cuioss/cui-jsf-test-basic[cui-jsf-test-basic]
   * Use for JSF component testing
   * Follow component test patterns
   * Include lifecycle tests

4. https://github.com/cuioss/cui-test-mockwebserver-junit5[cui-test-mockwebserver-junit5]
   * Use for testing HTTP client interactions
   * Mock HTTP server responses
   * Test request/response handling

=== Test Categories

==== Unit Tests

* Test single units in isolation
* Mock all dependencies
* Fast execution
* High maintainability

==== Integration Tests

* Test component interactions
* Minimal mocking
* Cover critical paths
* Include error scenarios
* Regular maintenance required

==== System Tests

* End-to-end scenarios
* Real dependencies where possible
* Cover main user flows
* Include performance criteria

== Quality Verification

For comprehensive quality verification processes, see <<../process/task-completion-standards.adoc#,Task Completion Standards>>.

=== Quality Analysis Tools

* SonarCloud for static code analysis
* JUnit for unit testing
* Mutation testing for test quality
* Regular code reviews
* Continuous integration checks (see <<../process/task-completion-standards.adoc#,Task Completion Standards>>)

=== Quality Metrics

* Code coverage
* Code duplication
* Complexity metrics
* Issue density
* Technical debt ratio

=== Best Practices

==== Test Quality

* Regular test review
* Mutation testing  
* Test failure analysis
* DRY in test utilities
* Clear test documentation
* Consistent patterns

[[ai-generated-code-detection]]
==== AI-Generated Code Detection and Elimination

**Critical Indicators of AI-Generated Test Code:**
* Method names exceeding 75 characters
* Excessive inline comments explaining obvious operations
* Repetitive test patterns with only minor variations
* Verbose @DisplayName annotations (54+ characters)
* Over-documentation with redundant explanations
* Meaningless constructor tests verifying trivial functionality

**Test Categories to Eliminate:**
1. **Meaningless Tests**: Tests that verify trivial functionality without business value
2. **Framework Behavior Tests**: Tests that verify framework functionality rather than application logic  
3. **Duplicate Logic Tests**: Tests that duplicate existing test scenarios without added value
4. **Over-Complex Unit Tests**: Tests that are disproportionately complex for the functionality being tested

**Removal Requirements:**
* **ELIMINATE**: Tests that verify trivial functionality without business value
* **REMOVE**: Comments explaining obvious operations
* **SIMPLIFY**: Overly verbose method and test names
* **CONSOLIDATE**: Identical test patterns into parameterized tests with @GeneratorsSource  
* **REPLACE**: Verbose @DisplayName with focused descriptions under 50 characters

**Examples of AI Artifacts to Remove:**
```java
// REMOVE: Meaningless constructor test
@Test
void shouldCreateWithValidParameters() {
    assertNotNull(new AccessTokenContent(validClaims));
}

// REMOVE: Framework behavior test
@Test  
void shouldLogInfoMessageWhenTokenValidatorIsInitialized() {
    // Testing framework logging behavior, not application logic
}

// REMOVE: Excessive inline comments
@Test
void shouldValidateToken() {
    // Create a token holder for testing purposes
    TestTokenHolder holder = new TestTokenHolder();
    // Set the token type to access token for validation
    holder.setTokenType(ACCESS_TOKEN);
    // Perform validation and check result
    assertTrue(validator.validate(holder.build()).isValid());
}
```

[[sonarqube-compliance]]
==== SonarQube Compliance

===== assertThrows Best Practices

Follow SonarQube rule: "Refactor the code of the lambda to have only one invocation possibly throwing a runtime exception"

**Problem:** Lambda expressions in `assertThrows` should contain only one statement that can throw the expected exception.

**Before (Violates SonarQube Rule):**
```java
@Test
void shouldThrowExceptionOnInvalidInput() {
    assertThrows(IllegalArgumentException.class, () -> {
        String input = "invalid";
        service.validateInput(input);
        service.processInput(input); // Multiple throwing statements
    });
}
```

**After (Compliant):**
```java
@Test
void shouldThrowExceptionOnInvalidInput() {
    // given
    String input = "invalid";
    service.validateInput(input); // Setup outside lambda
    
    // when/then
    assertThrows(IllegalArgumentException.class, () -> 
        service.processInput(input) // Only one throwing statement
    );
}
```


**Key Principles:**
* Move setup code outside the lambda expression
* Keep only the single method call that should throw the exception
* Use helper methods for complex throwing operations
* Maintain clear test structure with given/when/then pattern

=== Performance

* Fast test execution
* Efficient resource usage
* Parallel test execution where possible
* Regular performance monitoring

=== Review Process

Regular Review Points:

* After major feature completion
* Before creating pull requests
* During code review process
* Post-merge verification

=== Documentation

* Record quality findings
* Document remediation steps
* Note technical debt decisions
* Update quality metrics
* Track coverage changes

== Success Criteria

=== Test Coverage

* All coverage requirements met
* Critical paths fully covered
* Test quality sufficient
* No coverage regressions

=== Quality Analysis

For comprehensive quality gate processes, see <<../process/task-completion-standards.adoc#,Task Completion Standards>>.

* All quality gates passed
* New issues addressed
* Impact assessed
* Clear remediation paths
* Documentation complete

=== Security

* No critical vulnerabilities
* Security hotspots reviewed
* Dependencies verified
* Security standards met

== Maven Coverage Profile

For standardized build verification processes, see <<../process/task-completion-standards.adoc#,Task Completion Standards>>.

To verify code coverage in your project, use the Maven profile `-Pcoverage`:

For code coverage verification, use the coverage profile following the <<../process/task-completion-standards.adoc#,Task Completion Standards>>:

[source,bash]
----
./mvnw clean verify -Pcoverage
----

This profile will:

* Enable JaCoCo code coverage analysis
* Generate detailed coverage reports
* Enforce minimum coverage thresholds
* Fail the build if coverage requirements are not met

== See Also

* xref:../java/java-code-standards.adoc[Java Standards]
* xref:../documentation/javadoc-standards.adoc[Javadoc Standards]
* xref:../logging/README.adoc[Logging Standards]
